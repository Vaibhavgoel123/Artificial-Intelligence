{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UdoCOjs24PCvO8xXnI-R0EUvQCFFwolq",
      "authorship_tag": "ABX9TyPZOKKSi5ITA0v8j0fN3WDm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaibhavgoel123/Artificial-Intelligence/blob/Projects/Myproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "bzhuwSmufabs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Cn4pzFLLiclj"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive\")\n"
      ],
      "metadata": {
        "id": "EvwvLbPgf44B"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Core Idea\n",
        "In this project Bidirectional LSTM and Attention model is used to focus on important points in any sentence so that the overall sentence can be classified into one of the 3 categories:  \n",
        "1. Neutral\n",
        "2. Negative\n",
        "3. Positive\n",
        "\n",
        "Bidirectional LSTM is used so that the sentence can be validated properly and Attention model is used so as to focus on important keywords like **good**, **bad**, **excellent** etc. to understand the user sentiments regarding to that video.\n",
        "\n",
        "LSTM (Long Short Term Memory) is basically used to store or to understand the overall sentence while RNN (Recurrent Neural Networks) is only used for understanding the previous words or letters."
      ],
      "metadata": {
        "id": "qqm134ux8Bw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from model import Attention\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "# Dummy text\n",
        "texts = [\n",
        "    \"I love this video\",\n",
        "    \"This is terrible\",\n",
        "    \"This is horrible\",\n",
        "    \"This video is great\",\n",
        "    \"Excellent presentation\",\n",
        "    \"Amazing\",\n",
        "    \"Good but not great\"\n",
        "]\n",
        "\n",
        "labels=[2, 0, 0, 2, 2, 2, 1] #0-neg, 1-neutral, 2-positive\n",
        "num_words = 20000\n",
        "maxlen = 100\n",
        "embedding_dim = 128\n",
        "\n",
        "#Tokenizer\n",
        "tokenizer = Tokenizer(num_words=num_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(sequences, maxlen=maxlen)\n",
        "y = to_categorical(labels, num_classes=3)\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(num_words, embedding_dim, input_length=maxlen, mask_zero=True),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Attention(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3), #Randomly deactivates 30% of the neurons\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7zZTQ90hhSd",
        "outputId": "fcc39021-a6d7-4f20-ebd0-25ba32d1678b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=5, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyBUwuaXlHBx",
        "outputId": "27dc7640-2e0f-4b28-bfee-d1ad26c57ed4"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'attention_5' (of type Attention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 282ms/step - accuracy: 0.4381 - loss: 1.0987\n",
            "Epoch 2/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 165ms/step - accuracy: 0.5286 - loss: 1.0952\n",
            "Epoch 3/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 157ms/step - accuracy: 0.5619 - loss: 1.0905\n",
            "Epoch 4/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.7119 - loss: 1.0840\n",
            "Epoch 5/5\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 169ms/step - accuracy: 0.6119 - loss: 1.0841\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78aee5bdb530>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wk4SY3WYoa20"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('sentiment_model.keras')\n",
        "pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))\n",
        "\n",
        "print(\"Model and tokenizer saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQz9SmONl_B0",
        "outputId": "3b587153-4c31-4fe1-978c-75a16a030c43"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Web API\n",
        "Deployment of model is also necessary as its development so we are writing ```api.py``` file so as to connect this backend to the frontend in the form of API rather than as full code."
      ],
      "metadata": {
        "id": "TeeyLZV19Vmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile api.py\n",
        "# paste your FastAPI code here\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import numpy as np\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive\")\n",
        "from model import Attention\n",
        "\n",
        "# The Attention class must be defined or imported here for load_model to work\n",
        "# It's already defined in cell EvwvLbPgf44B and executed, so it's in scope.\n",
        "\n",
        "class Comments(BaseModel):\n",
        "  comments: list[str]\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Provide custom_objects to load the Attention layer correctly\n",
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/sentiment_model.keras\", custom_objects={\"Attention\": Attention})\n",
        "tokenizer = pickle.load(open(\"/content/drive/MyDrive/tokenizer.pkl\", \"rb\"))\n",
        "\n",
        "MAXLEN = 100\n",
        "labels = [\"negative\", \"neutral\", \"positive\"]\n",
        "\n",
        "@app.post(\"/predict_batch\")\n",
        "def predict_batch(data: Comments):\n",
        "  seq = tokenizer.texts_to_sequences(data.comments)\n",
        "  padded = pad_sequences(seq, maxlen=MAXLEN)\n",
        "\n",
        "  preds = model.predict(padded)\n",
        "  results = []\n",
        "\n",
        "  for probs in preds:\n",
        "    idx = int(np.argmax(probs))\n",
        "    results.append(labels[idx])\n",
        "\n",
        "\n",
        "  return {\"results\":results}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t96DuCZkrpF9",
        "outputId": "04a204fd-b9a5-43cb-84f3-74f757d77e35"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting api.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn pyngrok nest_asyncio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD2uQG2w6cbN",
        "outputId": "cd2d3995-423a-4625-9e7d-d2b1183008ba"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.123.10)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.40.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.50.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi) (3.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting the backend ```api.py``` to the browser to access the output."
      ],
      "metadata": {
        "id": "xZiPC_23-Db8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "\n",
        "ngrok.set_auth_token(\"YOUR_AUTH_TOKEN\")\n",
        "nest_asyncio.apply()\n",
        "public_url = ngrok.connect(8000)\n",
        "print(public_url)\n",
        "\n",
        "!uvicorn api:app --host 0.0.0.0 --port 8000 &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmcAPaRlsON7",
        "outputId": "d524ea18-99fc-42e2-a73a-04f410c52a5c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://nonnaturally-disjoinable-shakita.ngrok-free.dev\" -> \"http://localhost:8000\"\n",
            "2026-01-15 09:08:56.999219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768468137.036117   29881 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768468137.047654   29881 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768468137.073970   29881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768468137.074024   29881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768468137.074030   29881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768468137.074034   29881 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-01-15T09:08:59+0000 lvl=warn msg=\"failed to open private leg\" id=20033101a390 privaddr=localhost:8000 err=\"dial tcp [::1]:8000: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-01-15 09:09:05.767509: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'attention_5' (of type Attention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m29881\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     103.59.75.176:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     103.59.75.176:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     103.59.75.176:0 - \"\u001b[1mGET /docs HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     103.59.75.176:0 - \"\u001b[1mGET /openapi.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:965: UserWarning: Layer 'attention_5' (of type Attention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step\n",
            "\u001b[32mINFO\u001b[0m:     103.59.75.176:0 - \"\u001b[1mPOST /predict_batch HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "\u001b[32mINFO\u001b[0m:     103.59.75.176:0 - \"\u001b[1mPOST /predict_batch HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     103.59.75.176:0 - \"\u001b[1mGET /predict_batch HTTP/1.1\u001b[0m\" \u001b[31m405 Method Not Allowed\u001b[0m\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[32mINFO\u001b[0m:     103.59.75.176:0 - \"\u001b[1mPOST /predict_batch HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[32mINFO\u001b[0m:     103.59.75.176:0 - \"\u001b[1mPOST /predict_batch HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[32mINFO\u001b[0m:     103.59.75.176:0 - \"\u001b[1mPOST /predict_batch HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
            "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m29881\u001b[0m]\n"
          ]
        }
      ]
    }
  ]
}